#testing on ubuntu
name: build

on:
  push:
    branches:
      - 'master'
      - '*release*'
  pull_request:
    branches:
      - 'master'

jobs:
  
  spark32:
    if: "! contains(toJSON(github.event.commits.*.message), '[skip test]')"
    runs-on: macos-latest
    name: Build and Test on Apache Spark 3.2.x

    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK 8
        uses: actions/setup-java@v1
        with:
          java-version: 1.8
      - name: Install Python 3.7
        uses: actions/setup-python@v2
        with:
          python-version: 3.7.7
          architecture: x64
      - name: Install Python packages (Python 3.7)
        run: |
          python -m pip install --upgrade pip
          pip install pyspark==3.2.0 numpy
      - name: Build Spark NLP on Apache Spark 3.2.0
        run: |
          brew install sbt
          sbt clean
          sbt compile
          sbt -mem 4096 -Dis_spark32=true assemblyAndCopy
      - name: Test Spark NLP in Scala - Apache Spark 3.2.x
        run: |
          sbt -mem 4096 -Dis_spark32=true coverage test
      - name: Upload coverage data to Coveralls
        run: sbt coverageReport coveralls
        env:
          COVERALLS_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          COVERALLS_FLAG_NAME: Apache Spark 3.2.x - Scala 2.12
      - name: Test Spark NLP in Python - Apache Spark 3.2.x
        run: |
          cd python
          python3.7 -m run-tests

  spark_armv64_job:
    if: "! contains(toJSON(github.event.commits.*.message), '[skip ci]')"
    name: Build and Test on Apache Spark 3.2.x for arm64
    strategy:
      matrix:
        pyver: [cp38-cp38m]
    runs-on: ubuntu-18.04
    env:
      py: /opt/python/${{ matrix.pyver }}/bin/python
      img: quay.io/pypa/manylinux2014_aarch64  
    
    steps:
      - uses: actions/checkout@v2
      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@v1
      #- name: Set up JDK 8
      #  uses: actions/setup-java@v1
      #  with:
      #    java-version: 1.8
      #- name: Install Python 3.7
      #  uses: actions/setup-python@v2
      #  with:
      #    python-version: 3.7.7
      #    architecture: arm64   
      - name: Install and Run tests
        run: |
          docker run --rm -v ${{ github.workspace }}:/ws:rw --workdir=/ws \
            arm64v8/ubuntu:20.04 \
            bash -exc 'apt-get update && apt-get -y install python3 python3-pip python3-venv wget curl && \
            python3 -m pip install virtualenv && python3 -m venv py38-venv && \
            source py38-venv/bin/activate && \
            python3 -m pip install --upgrade pip && \
            python3 --version && \
            ln -fs /usr/share/zoneinfo/America/New_York /etc/localtime && export DEBIAN_FRONTEND=noninteractive && apt-get install -y tzdata && dpkg-reconfigure --frontend noninteractive tzdata && \
            apt-get -y install openjdk-8-jdk && \
            export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-arm64/ && \
            export PATH=$JAVA_HOME:$PATH && \
            uname -m && \
            
            whoami && \
            echo $PATH && \
            
            java -version && \
            
            echo $JAVA_HOME && \
            python3 --version && \
      

            
            pwd && \
            ls && \
            python3 -m pip install --upgrade pip && \
            python3 -m pip install pyspark==3.2.0 numpy && \
            apt-get update && \
            apt-get -y install apt-transport-https curl gnupg -yqq && \
            echo "deb https://repo.scala-sbt.org/scalasbt/debian all main" | tee /etc/apt/sources.list.d/sbt.list && \
            echo "deb https://repo.scala-sbt.org/scalasbt/debian /" | tee /etc/apt/sources.list.d/sbt_old.list && \
            curl -sL "https://keyserver.ubuntu.com/pks/lookup?op=get&search=0x2EE0EA64E40A89B84B2DF73499E82A75642AC823" && \
            apt-get -y install sbt && \
            sbt clean && \
            sbt compile && \
            sbt -mem 4096 -Dis_spark32=true assemblyAndCopy && \
            
            sbt -mem 4096 -Dis_spark32=true coverage test && \
              
            pwd && \
            ls && \
            python3 --version && \
            java -version && \
            cd python && \
            python3 -m run-tests && \
            deactivate'
